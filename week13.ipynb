{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMKxQW6CyhDcV1OJ8y+UJsv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aksHAGnHPZ_p"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=\"sk-\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQqpCvyyPyR2",
        "outputId": "dd2a073d-9a68-4d60-fa18-fe91ad8d9cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.12/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2025.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "max_retries = 3\n",
        "retry_delay = 5\n",
        "\n",
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0125\", #\"gpt-4\",\n",
        "        messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "          {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "        ]\n",
        "    )\n",
        "    print(response.choices[0].message['content'])\n",
        "    break\n",
        "  except openai.error.APIError as e:\n",
        "    print (f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries - 1:\n",
        "      print (f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep (retry_delay)\n",
        "    else:\n",
        "      print (\"Max r e t r i e s reached. Giving up.\")"
      ],
      "metadata": {
        "id": "Zb0t6KDuR7nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13dbb4e-c3ad-470b-ec24-2bcba13b90a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "규칙적인 운동은 건강에 많은 이점을 줍니다. 운동을 하면 심혈관 건강을 증진시키고 심장질환 위험을 낮춥니다. 또한 체중을 조절하고 대사를 촉진하여 비만을 예방하고 혈당 조절을 돕습니다. 운동은 또한 우울증과 스트레스를 줄이고 전체적인 기분을 개선시키며 자신감을 높이는 데도 도움이 됩니다. 마지막으로, 규칙적인 운동은 강하고 건강한 뼈 및 근육을 유지하고 관절 건강을 향상시키는 데 도움을 줍니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Function to get embeddings for a list of texts using OpenAI Embeddings API\n",
        "def get_embeddings(texts) :\n",
        "  response = openai.Embedding.create(\n",
        "      input=texts,\n",
        "      model=\"text-embedding-ada-002\"\n",
        "\n",
        "     # You can replace this with other available models\n",
        ")\n",
        "  # Extract and return the embeddings\n",
        "  return [embedding['embedding'] for embedding in response[ 'data' ]]\n",
        "\n",
        "# List of color words to embed\n",
        "color_words = [\"red\", \"blue\", \"yellow\", \"green\" , \"violet\" , \"cyan\", \"black\", \"white\"]\n",
        "\n",
        "# Get embeddings for the color words\n",
        "color_embeddings = get_embeddings(color_words)\n",
        "\n",
        "# Print the embeddings for each color word\n",
        "for word, embedding in zip(color_words, color_embeddings) :\n",
        "  print(f\"{word}: {embedding[:5]}...\") # Print only the first 5 dimensions for brevity\n",
        "  print(len(embedding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFu3PZyuP6-X",
        "outputId": "df41fa8c-c72d-4eaf-ef64-19e43dc69a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "red: [9.326533472631127e-06, -0.02476814016699791, -0.002384250983595848, -0.028791459277272224, -0.021199282258749008]...\n",
            "1536\n",
            "blue: [0.005474964156746864, -0.007486246060580015, 0.005678507499396801, -0.03110414557158947, -0.01965053379535675]...\n",
            "1536\n",
            "yellow: [0.007661858107894659, -0.024910997599363327, 0.004491548519581556, -0.02860249951481819, -0.01958620548248291]...\n",
            "1536\n",
            "green: [0.01546180434525013, -0.010975971817970276, 0.025183379650115967, -0.02092933841049671, -0.005648194346576929]...\n",
            "1536\n",
            "violet: [-0.006727131083607674, -0.018318135291337967, 0.0036361967213451862, -0.00567674869671464, -0.021194979548454285]...\n",
            "1536\n",
            "cyan: [0.021550633013248444, -0.014010688289999962, 0.008289773017168045, -0.02929886430501938, -0.016149088740348816]...\n",
            "1536\n",
            "black: [-0.015103082172572613, -0.031215764582157135, 0.00877943355590105, -0.03691864386200905, -0.01613996922969818]...\n",
            "1536\n",
            "white: [0.006292110309004784, -0.02457117661833763, 0.0002028137823799625, -0.014848269522190094, -0.0052642603404819965]...\n",
            "1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "response = openai.File.create(\n",
        "    file=open (\"mydata.jsonl\", \"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "\n",
        "file_id = response['id']\n",
        "print(f\"Uploaded file ID: {file_id}\")\n",
        "\n",
        "response = openai.FineTuningJob.create(\n",
        "    training_file=file_id,\n",
        "    mode1=-\"gpt-4o-mini-2024-07-18\"\n",
        ")\n",
        "\n",
        "fine_tune_id = response['id']\n",
        "print(f\"Fine-tune job ID: {fine_tune_id}\")\n",
        "\n",
        "while True:\n",
        "  response = openai.FineTune.retrieve(fine_tune_id)\n",
        "  status = response[ 'status' ]\n",
        "  if status in ['succeeded', 'failed']:\n",
        "    break\n",
        "print(f\"Fine-tune job status: {status}\")\n",
        "time.sleep(60)\n",
        "\n",
        "if status == 'succeeded' :\n",
        "  response = openai.Completion.create(\n",
        "    model_response['fine_tuned_model'] ,\n",
        "    prompt=\"Translate the following English text to French: 'Good night' \\n\\n###\\n\\n\",\n",
        "    max_tokens=50\n",
        "  )\n",
        "  print(f\"Fine-tuned model output: {response.choices[0].text.stript()} \" )\n",
        "else:\n",
        "  print (\"Fine-tuning job failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "8Z4uvoctULow",
        "outputId": "1f47fb86-8c54-43b0-c2f2-886d120cf2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.12/dist-packages/openai/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2398422066.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPENAI_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.12/dist-packages/openai/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def generate_image(prompt):\n",
        "  response = openai.Image.create(\n",
        "      # prompt=prompt,\n",
        "      # n=1,\n",
        "      # size=\"1024x1024\"\n",
        "\n",
        "      model=\"dall-e-3\",\n",
        "      prompt=\"a white siamese cat\",\n",
        "      size=\"1024x1024\",\n",
        "      quality=\"standard\",\n",
        "      n=1\n",
        "  )\n",
        "  image_url = response['data'][0]['url']\n",
        "  return image_url\n",
        "\n",
        "def save_image(image_url, filename) :\n",
        "  response = requests.get(image_url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  image.save(filename)\n",
        "\n",
        "prompt = \"A futuristic cityscape at sunset\"\n",
        "image_url = generate_image(prompt)\n",
        "print (f\"Image URL: {image_url}\")\n",
        "save_image (image_url, \"generated_image.png\" )\n",
        "print (\"Image saved as generated_image.png\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCP8n-9MfOQo",
        "outputId": "3c5ecb2a-691d-4dda-d640-0a3328ad36ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-5ry0LkkMcAL21sBYTbBI948C/user-Ta358DHvAB0VtotAWl38aFTt/img-FRHGfOnoMyYwrJyhtYp8DjPb.png?st=2025-11-25T05%3A00%3A48Z&se=2025-11-25T07%3A00%3A48Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=32836cae-d25f-4fe9-827b-1c8c59c442cc&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-11-25T05%3A30%3A52Z&ske=2025-11-26T05%3A30%3A52Z&sks=b&skv=2024-08-04&sig=xrjo/OXUPutCc1x3KvVUf7HU3suUbU9mrMCv4jIS4dg%3D\n",
            "Image saved as generated_image.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "def generate_code(prompt, model=\"gpt-3.5-turbo-instruct\", max_tokens=1000):\n",
        "  try:\n",
        "    response = openai.Completion.create(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    max_tokens=max_tokens,\n",
        "    temperature=0,\n",
        "    n=1,\n",
        "    stop=None\n",
        "    )\n",
        "\n",
        "    code = response.choices[0].text.strip()\n",
        "    return code\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    return None\n",
        "\n",
        "prompt = \"Write a C code that computes Fibonacci number using memoization.\"\n",
        "\n",
        "generated_code = generate_code (prompt )\n",
        "\n",
        "if generated_code:\n",
        "  print (\"Generated Code: \\n\")\n",
        "  print (generated_code)\n",
        "else:\n",
        "  print(\"Failed to generate code.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1cdXFfVmNas",
        "outputId": "307ec81c-b99d-4e41-8c0e-8d87537d889f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code: \n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "// Function to compute Fibonacci number using memoization\n",
            "int fib(int n, int memo[])\n",
            "{\n",
            "    // Base cases\n",
            "    if (n == 0 || n == 1)\n",
            "        return n;\n",
            "\n",
            "    // Check if the value is already computed\n",
            "    if (memo[n] != -1)\n",
            "        return memo[n];\n",
            "\n",
            "    // Compute and store the value in the memo array\n",
            "    memo[n] = fib(n-1, memo) + fib(n-2, memo);\n",
            "\n",
            "    // Return the computed value\n",
            "    return memo[n];\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    int n;\n",
            "    printf(\"Enter the value of n: \");\n",
            "    scanf(\"%d\", &n);\n",
            "\n",
            "    // Initialize the memo array with -1\n",
            "    int memo[n+1];\n",
            "    for (int i = 0; i <= n; i++)\n",
            "        memo[i] = -1;\n",
            "\n",
            "    // Call the fib function and print the result\n",
            "    printf(\"Fibonacci number at position %d is %d\", n, fib(n, memo));\n",
            "\n",
            "    return 0;\n",
            "}\n",
            "\n",
            "/*\n",
            "Output:\n",
            "\n",
            "Enter the value of n: 6\n",
            "Fibonacci number at position 6 is 8\n",
            "*/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "upload_response = openai.File.create(\n",
        "  file=open(\"king-style-chat.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "print(\"Upload Response:\")\n",
        "print(upload_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0h0kbQypQkI",
        "outputId": "cbe53990-dfba-4e61-c55d-8b01d60b11c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Response:\n",
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-LpTAoPtxs547GaMr67qLJW\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 57615,\n",
            "  \"created_at\": 1764051331,\n",
            "  \"expires_at\": null,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "# Function to transcribe audio using OpenAI Audio API\n",
        "def transcribe_audio(file_path, model=\"whisper-1\", response_format=\"json\" , temperature=0.1, language=None, prompt=None) :\n",
        "  with open (file_path , \"rb\") as audio_file:\n",
        "    response= openai.Audio.transcribe(\n",
        "      file=audio_file,\n",
        "      model=model,\n",
        "      response_format=response_format,\n",
        "      temperature=temperature,\n",
        "      language=language,\n",
        "      prompt=prompt\n",
        "  )\n",
        "  return response\n",
        "\n",
        "file_path = 'Dracula.mp3'\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(\"Transcription Response:\")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX1yTIuRtDB3",
        "outputId": "4a1996ac-d1b1-4427-f466-b3b07cd7814f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Response:\n",
            "{\n",
            "  \"text\": \"Now that we've found where the enemy's lurking, nothing can stand in our way. Since we are facing the forces of darkness, we must be the cold light of day. We are the lanterns that burn in the lighthouse, the candles in the crypt. We are the light. Let there be light. This is a war and we must be the victors. There's too much to lose if we fail. We'll cross the seas like a band of crusaders, searching for some precious grail. We are the embers that glow in the winter, the diamonds in the mine. Let's take our torches and pray God will show us a sign. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the other. When the great battle commences, surely the light will prevail. We will break down his defenses, he will fall. And the sun will rise. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the other.\",\n",
            "  \"usage\": {\n",
            "    \"type\": \"duration\",\n",
            "    \"seconds\": 116\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}